# 第一章 引言

> 抽象和形式化的任务对人类而言是最困难的脑力任务之一，比如繁琐的数学计算公式，但这对计算机而言却属于最容易的；而对于难以形式化和抽象的任务，往往人类能很容易的完成，比如鉴赏美丑，但着对于计算机而言却是一个挑战。为了让计算机能像人一样轻松并高效的完成非形式化的任务，人工智能由此提出。

## 硬编码阶段

早期人工智能的实现是基于计算机的**硬编码**，人们希望通过建立简化事物放入模型，就是将所有的可能性输入数据库，应用时就是根据已有的数据和算法推导出结果，这需要大量的人力来输入数据，但结果往往不如人意，比如识别一张人刷牙的照片，可能就识别成一个人在抽烟

## 机器学习阶段

* 由硬编码的困难发现，AI 系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力，这种能力称为**机器学习**( machine learning )
* 许多人工智能任务都可通过如下方式解决：先提取一个合适的特征集（数据的表示），然后将这些特征提供给简单的机器学习算法
> 机器学习算法比如：逻辑回归 ( logistic regression )、朴素贝叶斯 ( native Bayes )；但特征集，即数据的表示 ( representation )，往往难以提取得到，为解决这一问题，提出了表示学习

### 使用算法得到数据的表示 - 表示学习 ( representation learning )

* 使用机器学习来发掘数据的表示。经过学习得到的特征集往往比手动输入的原始数据表示能更好的描述数据特征
* 表示学习算法典例：自编码器 ( autoencoder )，是由一个编码器 ( encoder ) 函数和一个解码器 ( decoder ) 函数组合而成的。编码器函数将输入数据转换成一种不同的数据表示，之后解码器函数则将这个新的数据表示转换回原来的形式
* 自编码器是一种数据的压缩算法，其中数据的压缩和解压缩函数是数据相关的、有损的、从样本中自动学习的。在大部分提到自动编码器的场合，压缩和解压缩的函数是通过神经网络实现的
* 当提取数据的特征集和设计学习原始特征集的算法时，最主要的方法往往是提取出能解释数据的**factors of variation**( 变差因素 ），factor 指影响数据不同的根源。比如分析语音记录时，factors of variation 就包括说话者的年龄、性别、口音和内容等等。显然，从原始数据里提取这种如此抽象的特征集十分困难

### 用简单的数据表示来构造复杂的数据表示 - 深度学习 ( deep learning )

